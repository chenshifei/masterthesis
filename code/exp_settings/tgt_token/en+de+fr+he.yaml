he_tgt_token: !Experiment
  exp_global: !ExpGlobal
    model_file: output/{EXP}/en+de+fr+he.mod
    log_file: output/{EXP}/en+de+fr+he.log
    default_layer_dim: 512
    dropout: 0.1
    placeholders:
      DATA_IN_BASE: corpus/data/tgt_token/en+de+fr_en+de+fr
      DATA_OUT_BASE: corpus/preproc/tgt_token/en+de+fr_en+de+fr
      DATA_IN: corpus/data/tgt_token/en+de+fr+he_en+de+fr+he
      DATA_OUT: corpus/preproc/tgt_token/en+de+fr+he_en+de+fr+he
  preproc: !PreprocRunner
    overwrite: True
    tasks:
    - !PreprocNormalize
      in_files:
      - '{DATA_IN}/train.src'
      - '{DATA_IN}/train.tgt'
      - '{DATA_IN}/test.src'
      - '{DATA_IN}/test.tgt'
      out_files:
      - '{DATA_OUT}/train.tok.norm.src'
      - '{DATA_OUT}/train.tok.norm.tgt'
      - '{DATA_OUT}/test.tok.norm.src'
      - '{DATA_OUT}/test.tok.norm.tgt'
      specs:
      - filenum: all
        normalizers:
        - !NormalizerLower {}
    - !PreprocVocab
      in_files:
      - '{DATA_OUT}/train.tok.norm.src'
      - '{DATA_OUT}/train.tok.norm.tgt'
      out_files:
      - '{DATA_OUT}/train.src.vocab'
      - '{DATA_OUT}/train.tgt.vocab'
      specs:
      - filenum: all
        filters:
        - !VocabFiltererFreq
            min_freq: 2
  model: !DefaultTranslator
    src_reader: !PlainTextReader
      vocab: !Vocab
        vocab_file: '{DATA_OUT}/train.src.vocab'
    trg_reader: !PlainTextReader
      vocab: !Vocab
        vocab_file: '{DATA_OUT}/train.tgt.vocab'
    src_embedder: !PretrainedSimpleWordEmbedder
      emb_dim: 300
      filename: embeddings/wiki.en+de+fr+he.align.vec
      vocab: !Vocab
        vocab_file: '{DATA_OUT}/train.src.vocab'
    encoder: !UniLSTMSeqTransducer
      layers: 1
    attender: !MlpAttender
      hidden_dim: 512
      state_dim: 512
      input_dim: 512
    decoder: !AutoRegressiveDecoder
      embedder: !PretrainedSimpleWordEmbedder
        emb_dim: 300
        filename: embeddings/wiki.en+de+fr+he.align.vec
        vocab: !Vocab
          vocab_file: '{DATA_OUT}/train.tgt.vocab'
      bridge: !CopyBridge {}
  train: !SimpleTrainingRegimen
    batcher: !SrcBatcher
        batch_size: 16
    run_for_epochs: 20
    src_file: '{DATA_OUT_BASE}/train.tok.norm.filter.src'
    trg_file: '{DATA_OUT_BASE}/train.tok.norm.filter.tgt'
    restart_trainer: True
    trainer: !AdamTrainer
      alpha: 0.0002
    lr_decay: 0.5
    dev_tasks:
      - !AccuracyEvalTask
        eval_metrics: bleu
        src_file: '{DATA_OUT_BASE}/dev.tok.norm.src'
        ref_file: '{DATA_OUT_BASE}/dev.tok.norm.tgt'
        hyp_file: output/{EXP}.dev_hyp
  evaluate:
    - !AccuracyEvalTask
      eval_metrics: bleu
      src_file: '{DATA_OUT}/test.tok.norm.src'
      ref_file: '{DATA_OUT}/test.tok.norm.tgt'
      hyp_file: output/{EXP}.test_hyp
      inference: !AutoRegressiveInference
        reporter:
        - !AttentionReporter {} # plot attentions
        - !ReferenceDiffReporter {} # difference highlighting
        - !CompareMtReporter {} # analyze MT outputs
        - !OOVStatisticsReporter # report on recovered OOVs, fantasized new words, etc.
          train_trg_file: '{DATA_OUT_BASE}/train.tok.norm.filter.tgt'
